"""
REXA ì¹´ì¹´ì˜¤í†¡ ë´‡ ì„œë²„
- ì‚¬ìš©ì ìš”ì²­ ì‹œ ë‰´ìŠ¤ ì „ë‹¬
- RAG ê¸°ë°˜ ì§ˆì˜ì‘ë‹µ
"""

import logging
import os
import asyncio
import uuid
from datetime import datetime
from typing import Optional, Any
from collections import deque

from fastapi import FastAPI
from pydantic import BaseModel
from openai import OpenAI, OpenAIError, APITimeoutError
import numpy as np
import pickle

# ê³µí†µ í•¨ìˆ˜ ì„í¬íŠ¸
from common import (
    search_naver_news,
    crawl_news_content,
    save_all_news_background,
    init_google_sheets,
    init_csv_file
)

# Redis for queue management (optional)
try:
    import redis.asyncio as redis
    from redis.asyncio import Redis
    REDIS_AVAILABLE = True
except ImportError:
    REDIS_AVAILABLE = False
    Redis = Any
    logging.warning("redis package not installed. Using in-memory queue.")

# ================================================================================
# ë¡œê¹… ì„¤ì •
# ================================================================================

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

app = FastAPI(
    title="REXA - Real Estate Expert Assistant",
    description="ì¹´ì¹´ì˜¤í†¡ ë¶€ë™ì‚° ë‰´ìŠ¤ë´‡ + RAG",
    version="3.0.0"
)

# ================================================================================
# í™˜ê²½ë³€ìˆ˜ & ì„¤ì •
# ================================================================================

# Upstage Solar API
UPSTAGE_API_KEY = os.getenv("UPSTAGE_API_KEY")
API_TIMEOUT = int(os.getenv("API_TIMEOUT", 3))

# Redis (optional)
REDIS_HOST = os.getenv("REDIS_HOST", "localhost")
REDIS_PORT = int(os.getenv("REDIS_PORT", 6379))
REDIS_DB = int(os.getenv("REDIS_DB", 0))
REDIS_PASSWORD = os.getenv("REDIS_PASSWORD", None)

# Queue
WEBHOOK_QUEUE_NAME = "rexa:webhook_queue"
WEBHOOK_PROCESSING_QUEUE = "rexa:processing_queue"
WEBHOOK_FAILED_QUEUE = "rexa:failed_queue"
MAX_RETRY_ATTEMPTS = int(os.getenv("MAX_RETRY_ATTEMPTS", 3))
QUEUE_PROCESS_INTERVAL = int(os.getenv("QUEUE_PROCESS_INTERVAL", 5))

# Health Check
HEALTH_CHECK_INTERVAL = int(os.getenv("HEALTH_CHECK_INTERVAL", 5))
MAX_UNHEALTHY_COUNT = int(os.getenv("MAX_UNHEALTHY_COUNT", 3))

# ================================================================================
# ê¸€ë¡œë²Œ ë³€ìˆ˜
# ================================================================================

# Solar API client
client = OpenAI(
    api_key=UPSTAGE_API_KEY,
    base_url="https://api.upstage.ai/v1/solar",
    timeout=API_TIMEOUT
)

# Redis
redis_client: Optional[Any] = None
use_in_memory_queue = False

# In-memory queue fallback
in_memory_webhook_queue: deque = deque()
in_memory_processing_queue: deque = deque()
in_memory_failed_queue: deque = deque()

# Health
server_healthy = True
unhealthy_count = 0
last_health_check = datetime.now()

# News sessions (user_id -> news_data)
news_sessions = {}

# RAG embeddings
article_chunks = []
chunk_embeddings = []

# ================================================================================
# Pydantic ëª¨ë¸
# ================================================================================

class DetailParams(BaseModel):
    prompt: dict

class Action(BaseModel):
    params: dict
    detailParams: dict

class RequestBody(BaseModel):
    action: Action

class QueuedRequest(BaseModel):
    request_id: str
    request_body: dict
    timestamp: str
    retry_count: int = 0
    error_message: Optional[str] = None

class HealthStatus(BaseModel):
    status: str
    model: str
    mode: str
    server_healthy: bool
    last_check: str
    redis_connected: bool
    queue_size: int
    processing_queue_size: int
    failed_queue_size: int

# ================================================================================
# RAG ì„ë² ë”© ë¡œë“œ
# ================================================================================

try:
    with open("embeddings.pkl", "rb") as f:
        data = pickle.load(f)
        article_chunks = data["chunks"]
        chunk_embeddings = data["embeddings"]
    logger.info(f"âœ… Loaded {len(article_chunks)} chunks from embeddings.pkl")
except FileNotFoundError:
    logger.warning("âš ï¸ embeddings.pkl not found - RAG disabled")
except Exception as e:
    logger.error(f"âŒ Failed to load embeddings: {e}")

# ================================================================================
# RAG Helper Functions
# ================================================================================

def cosine_similarity(a, b):
    """Calculate cosine similarity"""
    from numpy import dot
    from numpy.linalg import norm
    return dot(a, b) / (norm(a) * norm(b))

async def get_relevant_context(prompt: str, top_n: int = 2) -> str:
    """Get relevant context from embeddings for RAG"""
    if not chunk_embeddings or not article_chunks:
        return ""
    
    try:
        embedding_dim = len(chunk_embeddings[0])
        
        # Solar embedding
        q_embedding = client.embeddings.create(
            input=prompt,
            model="solar-embedding-1-large-query"
        ).data[0].embedding
        
        # Calculate similarities
        similarities = [cosine_similarity(q_embedding, emb) for emb in chunk_embeddings]
        top_indices = np.argsort(similarities)[-top_n:][::-1]
        selected_context = "\n\n".join([article_chunks[i] for i in top_indices])
        
        return selected_context
    except Exception as e:
        logger.error(f"âŒ Error getting relevant context: {e}")
        return ""

# ================================================================================
# Redis & Queue ê´€ë¦¬
# ================================================================================

async def init_redis():
    """Initialize Redis connection"""
    global redis_client, use_in_memory_queue
    
    if not REDIS_AVAILABLE:
        logger.warning("âš ï¸ Redis package not installed - using in-memory queue")
        use_in_memory_queue = True
        return
    
    try:
        redis_client = await redis.Redis(
            host=REDIS_HOST,
            port=REDIS_PORT,
            db=REDIS_DB,
            password=REDIS_PASSWORD,
            decode_responses=True,
            socket_connect_timeout=5
        )
        await redis_client.ping()
        logger.info(f"âœ… Redis connected: {REDIS_HOST}:{REDIS_PORT}")
        use_in_memory_queue = False
    except Exception as e:
        logger.warning(f"âš ï¸ Redis connection failed: {e}")
        use_in_memory_queue = True

async def close_redis():
    """Close Redis connection"""
    global redis_client
    if redis_client:
        await redis_client.close()
        logger.info("âœ… Redis connection closed")

async def enqueue_webhook_request(request_id: str, request_body: dict):
    """Add webhook request to queue"""
    queued_req = QueuedRequest(
        request_id=request_id,
        request_body=request_body,
        timestamp=datetime.now().isoformat()
    )
    
    if use_in_memory_queue:
        in_memory_webhook_queue.append(queued_req)
        logger.info(f"ğŸ“¥ Request queued (in-memory): {len(in_memory_webhook_queue)}")
        return
    
    if not redis_client:
        in_memory_webhook_queue.append(queued_req)
        return
    
    try:
        await redis_client.lpush(WEBHOOK_QUEUE_NAME, queued_req.model_dump_json())
        queue_size = await redis_client.llen(WEBHOOK_QUEUE_NAME)
        logger.info(f"ğŸ“¥ Request queued (Redis): {queue_size}")
    except Exception as e:
        logger.error(f"âŒ Failed to enqueue: {e}")
        in_memory_webhook_queue.append(queued_req)

async def get_queue_sizes():
    """Get sizes of all queues"""
    if use_in_memory_queue:
        return (
            len(in_memory_webhook_queue),
            len(in_memory_processing_queue),
            len(in_memory_failed_queue)
        )
    
    if not redis_client:
        return (0, 0, 0)
    
    try:
        webhook_size = await redis_client.llen(WEBHOOK_QUEUE_NAME)
        processing_size = await redis_client.llen(WEBHOOK_PROCESSING_QUEUE)
        failed_size = await redis_client.llen(WEBHOOK_FAILED_QUEUE)
        return (webhook_size, processing_size, failed_size)
    except:
        return (0, 0, 0)

# ================================================================================
# Background Tasks
# ================================================================================

async def health_check_monitor():
    """Background task to monitor server health"""
    global server_healthy, unhealthy_count, last_health_check
    
    while True:
        try:
            await asyncio.sleep(HEALTH_CHECK_INTERVAL)
            
            # Check Solar API
            try:
                test_response = client.chat.completions.create(
                    model="solar-mini",
                    messages=[{"role": "user", "content": "ping"}],
                    max_tokens=10,
                    timeout=2
                )
                
                server_healthy = True
                unhealthy_count = 0
                last_health_check = datetime.now()
                
            except Exception as e:
                unhealthy_count += 1
                logger.warning(f"âš ï¸ Health check failed ({unhealthy_count}/{MAX_UNHEALTHY_COUNT})")
                
                if unhealthy_count >= MAX_UNHEALTHY_COUNT:
                    server_healthy = False
                    logger.error(f"âŒ Server marked as unhealthy")
                
        except Exception as e:
            logger.error(f"âŒ Health check monitor error: {e}")

async def queue_processor():
    """Background task to process queued requests"""
    while True:
        try:
            await asyncio.sleep(QUEUE_PROCESS_INTERVAL)
            
            if use_in_memory_queue:
                while len(in_memory_webhook_queue) > 0:
                    req = in_memory_webhook_queue.popleft()
                    
                    try:
                        result = await process_solar_rag_request(req.request_body)
                        logger.info(f"âœ… Processed queued request {req.request_id[:8]}")
                    except Exception as e:
                        req.retry_count += 1
                        req.error_message = str(e)
                        
                        if req.retry_count < MAX_RETRY_ATTEMPTS:
                            in_memory_webhook_queue.append(req)
                        else:
                            in_memory_failed_queue.append(req)
                            logger.error(f"âŒ Request {req.request_id[:8]} failed")
                continue
            
            # Redis queue processing (ìƒëµ ê°€ëŠ¥)
            
        except Exception as e:
            logger.error(f"âŒ Queue processor error: {e}")

# ================================================================================
# Core Processing Functions
# ================================================================================

async def process_solar_rag_request(request_body: dict) -> dict:
    """Process request with Solar API + RAG or News context"""
    try:
        action = request_body.get("action", {})
        detail_params = action.get("detailParams", {})
        user_message_data = detail_params.get("prompt", {})
        user_message = user_message_data.get("value", "").strip()
        
        # ì‚¬ìš©ì ID ì¶”ì¶œ
        user_request = request_body.get("userRequest", {})
        user_info = user_request.get("user", {})
        user_id = user_info.get("id", "default")
        
        if not user_message:
            return {
                "version": "2.0",
                "template": {
                    "outputs": [
                        {"simpleText": {"text": "ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”."}}
                    ]
                }
            }
        
        logger.info(f"ğŸ’¬ User message: {user_message}")
        
        # ì»¨í…ìŠ¤íŠ¸ ê²°ì •
        context = ""
        context_source = "general"
        
        # ë‰´ìŠ¤ ì„¸ì…˜ í™•ì¸
        if user_id in news_sessions:
            news_data = news_sessions[user_id]
            context = f"ë‹¤ìŒì€ ìµœì‹  ë¶€ë™ì‚° ë‰´ìŠ¤ì…ë‹ˆë‹¤:\n\nì œëª©: {news_data['title']}\n\n{news_data['content']}\n\nìœ„ ë‰´ìŠ¤ë¥¼ ì°¸ê³ í•˜ì—¬ ë‹µë³€í•´ì£¼ì„¸ìš”."
            context_source = "news"
            logger.info(f"ğŸ“° Using news context")
        else:
            # RAG ì»¨í…ìŠ¤íŠ¸ ì‚¬ìš©
            context = await get_relevant_context(user_message, top_n=2)
            if context:
                context = f"ë‹¤ìŒì€ ê´€ë ¨ ì •ë³´ì…ë‹ˆë‹¤:\n\n{context}\n\nìœ„ ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬ ë‹µë³€í•´ì£¼ì„¸ìš”."
                context_source = "rag"
                logger.info(f"ğŸ“š Using RAG context")
        
        # System prompt
        system_prompt = "ë‹¹ì‹ ì€ ë¶€ë™ì‚° ì „ë¬¸ AI ì–´ì‹œìŠ¤í„´íŠ¸ REXAì…ë‹ˆë‹¤."
        if context:
            system_prompt += f"\n\n{context}"
        
        # Solar API í˜¸ì¶œ
        response = client.chat.completions.create(
            model="solar-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_message}
            ],
            max_tokens=500,
            timeout=API_TIMEOUT
        )
        
        ai_response = response.choices[0].message.content.strip()
        logger.info(f"âœ… Solar API response (context: {context_source})")
        
        # ì¹´ì¹´ì˜¤í†¡ ì‘ë‹µ
        kakao_response = {
            "version": "2.0",
            "template": {
                "outputs": [
                    {"simpleText": {"text": ai_response}}
                ]
            }
        }
        
        # ë‰´ìŠ¤ ëª¨ë“œì¼ ê²½ìš° Quick Reply ì¶”ê°€
        if context_source == "news":
            news_data = news_sessions[user_id]
            kakao_response["template"]["quickReplies"] = [
                {
                    "label": "ë‰´ìŠ¤ ì›ë¬¸ ë³´ê¸°",
                    "action": "webLink",
                    "webLinkUrl": news_data['url']
                },
                {
                    "label": "ë‹¤ë¥¸ ì§ˆë¬¸í•˜ê¸°",
                    "action": "message",
                    "messageText": "ì´ ë‰´ìŠ¤ì—ì„œ í•µì‹¬ì€ ë­ì•¼?"
                }
            ]
        
        return kakao_response
        
    except Exception as e:
        logger.error(f"âŒ Solar API error: {e}")
        raise

# ================================================================================
# API ì—”ë“œí¬ì¸íŠ¸
# ================================================================================

@app.post("/news")
async def news_bot(request: RequestBody):
    """ë¶€ë™ì‚° ë‰´ìŠ¤ë´‡ - ì‚¬ìš©ì ìš”ì²­ ì‹œ"""
    request_id = str(uuid.uuid4())
    
    logger.info("=" * 50)
    logger.info(f"ğŸ“° News bot request: {request_id[:8]}")
    
    try:
        # ì‚¬ìš©ì ID ì¶”ì¶œ
        request_dict = request.model_dump()
        user_request = request_dict.get("userRequest", {})
        user_info = user_request.get("user", {})
        user_id = user_info.get("id", "default")
        
        # ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰ (20ê°œ)
        news_items = search_naver_news("ë¶€ë™ì‚°", display=20)
        
        if not news_items or len(news_items) == 0:
            return {
                "version": "2.0",
                "template": {
                    "outputs": [
                        {"simpleText": {"text": "ë‰´ìŠ¤ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."}}
                    ]
                }
            }
        
        logger.info(f"ğŸ“Š í•„í„°ë§ ì™„ë£Œ: ì´ {len(news_items)}ê°œ ë¶€ë™ì‚° ê´€ë ¨ ë‰´ìŠ¤")
        
        # ìƒìœ„ 3ê°œ ë¡œê¹…
        for idx, item in enumerate(news_items[:3]):
            logger.info(
                f"   [{idx+1}] {item['title'][:40]}... "
                f"(ì ìˆ˜: {item.get('relevance_score', 0)}, "
                f"ì§€ì—­: {item.get('region', 'N/A')})"
            )
        
        # ì²« ë²ˆì§¸ ë‰´ìŠ¤ í¬ë¡¤ë§
        first_news = news_items[0]
        
        # Rate Limit ë°©ì§€ ì¬ì‹œë„ ë¡œì§
        first_news_content = ""
        max_retries = 2
        for attempt in range(max_retries):
            try:
                first_news_content = crawl_news_content(first_news['link'])
                if first_news_content and "ë³¸ë¬¸ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤" not in first_news_content:
                    break
                if attempt < max_retries - 1:
                    logger.warning(f"âš ï¸ í¬ë¡¤ë§ ì¬ì‹œë„ {attempt + 1}/{max_retries}")
                    await asyncio.sleep(3)
            except Exception as e:
                logger.error(f"âŒ í¬ë¡¤ë§ ì‹œë„ {attempt + 1} ì‹¤íŒ¨: {e}")
                if attempt < max_retries - 1:
                    await asyncio.sleep(3)
                else:
                    first_news_content = first_news['description']
        
        # ì„¸ì…˜ì— ì €ì¥
        news_sessions[user_id] = {
            "title": first_news['title'],
            "description": first_news['description'],
            "content": first_news_content,
            "url": first_news['link'],
            "timestamp": datetime.now().isoformat()
        }
        
        # Solar AI ìš”ì•½ ìƒì„±
        try:
            summary_prompt = f"ë‹¤ìŒ ë‰´ìŠ¤ë¥¼ 3-4ê°œì˜ ì™„ì „í•œ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”.\n\nì œëª©: {first_news['title']}\n\në³¸ë¬¸: {first_news_content[:1500]}"
            
            response = client.chat.completions.create(
                model="solar-mini",
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ë¶€ë™ì‚° ë‰´ìŠ¤ ì „ë¬¸ ìš”ì•½ AIì…ë‹ˆë‹¤."},
                    {"role": "user", "content": summary_prompt}
                ],
                max_tokens=300,
                timeout=API_TIMEOUT
            )
            
            summary = response.choices[0].message.content.strip()
            logger.info(f"âœ… Solar AI summary generated")
            
        except Exception as e:
            logger.error(f"âŒ Summary generation failed: {e}")
            summary = first_news['description']
            last_period = summary.rfind('.')
            if last_period > 0:
                summary = summary[:last_period + 1]
        
        # ë°±ê·¸ë¼ìš´ë“œ ì €ì¥
        asyncio.create_task(save_all_news_background(news_items, user_id))
        
        # ì¹´ì¹´ì˜¤í†¡ ì‘ë‹µ
        return {
            "version": "2.0",
            "template": {
                "outputs": [
                    {
                        "simpleText": {
                            "text": f"ğŸ“° ì˜¤ëŠ˜ì˜ ë¶€ë™ì‚° ë‰´ìŠ¤ (ì´ {len(news_items)}ê±´)\n\nã€{first_news['title']}ã€‘\n\n{summary}\n\nğŸ’¬ ì´ ë‰´ìŠ¤ì— ëŒ€í•´ ê¶ê¸ˆí•œ ì ì„ ë¬¼ì–´ë³´ì„¸ìš”!"
                        }
                    }
                ],
                "quickReplies": [
                    {
                        "label": "í•µì‹¬ ë‚´ìš©ì€?",
                        "action": "message",
                        "messageText": "ì´ ë‰´ìŠ¤ì˜ í•µì‹¬ì€ ë­ì•¼?"
                    },
                    {
                        "label": "ì‹œì¥ ì˜í–¥ì€?",
                        "action": "message",
                        "messageText": "ì´ê²Œ ë¶€ë™ì‚° ì‹œì¥ì— ì–´ë–¤ ì˜í–¥ì„ ì¤„ê¹Œ?"
                    },
                    {
                        "label": "ì›ë¬¸ ë³´ê¸°",
                        "action": "webLink",
                        "webLinkUrl": first_news['link']
                    }
                ]
            }
        }
        
    except Exception as e:
        logger.error(f"âŒ News bot error: {e}")
        return {
            "version": "2.0",
            "template": {
                "outputs": [
                    {"simpleText": {"text": "ë‰´ìŠ¤ë¥¼ ì²˜ë¦¬í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."}}
                ]
            }
        }

@app.post("/custom")
async def generate_custom(request: RequestBody):
    """REXA ì±—ë´‡ (RAG) - ì¹´ì¹´ì˜¤í†¡ 5ì´ˆ ì œí•œ ëŒ€ì‘"""
    request_id = str(uuid.uuid4())
    
    logger.info("=" * 50)
    logger.info(f"ğŸ“¨ RAG request: {request_id[:8]}")
    
    try:
        result = await process_solar_rag_request(request.model_dump())
        logger.info(f"âœ… Request {request_id[:8]} completed")
        return result
        
    except APITimeoutError:
        logger.warning(f"â° Timeout - enqueueing {request_id}")
        await enqueue_webhook_request(request_id, request.model_dump())
        
        return {
            "version": "2.0",
            "template": {
                "outputs": [
                    {"simpleText": {"text": "ë‹µë³€ ìƒì„±ì— ì‹œê°„ì´ ê±¸ë¦¬ê³  ìˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì§ˆë¬¸í•´ì£¼ì„¸ìš”."}}
                ]
            }
        }
        
    except Exception as e:
        logger.error(f"âŒ Error: {e}")
        return {
            "version": "2.0",
            "template": {
                "outputs": [
                    {"simpleText": {"text": "ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ í•œë²ˆ ì§ˆë¬¸í•´ì£¼ì„¸ìš”."}}
                ]
            }
        }

@app.get("/health")
async def health_check() -> HealthStatus:
    """Health check endpoint"""
    queue_size, processing_size, failed_size = await get_queue_sizes()
    
    return HealthStatus(
        status="healthy" if server_healthy else "unhealthy",
        model="solar-mini",
        mode="rexa_chatbot_rag_news",
        server_healthy=server_healthy,
        last_check=last_health_check.isoformat(),
        redis_connected=(redis_client is not None and not use_in_memory_queue),
        queue_size=queue_size,
        processing_queue_size=processing_size,
        failed_queue_size=failed_size
    )

@app.get("/health/ping")
async def health_ping():
    """Simple ping endpoint"""
    return {
        "alive": True,
        "healthy": server_healthy,
        "timestamp": datetime.now().isoformat(),
        "rag_enabled": len(chunk_embeddings) > 0,
        "news_sessions": len(news_sessions)
    }

# ================================================================================
# Startup & Shutdown
# ================================================================================

@app.on_event("startup")
async def startup_event():
    """Initialize resources on startup"""
    logger.info("=" * 70)
    logger.info("ğŸš€ Starting REXA Bot Server...")
    logger.info("=" * 70)
    
    # RAG ìƒíƒœ
    if len(chunk_embeddings) > 0:
        logger.info(f"âœ… RAG ENABLED: {len(chunk_embeddings)} chunks")
    else:
        logger.warning("âš ï¸ RAG DISABLED: No embeddings loaded")
    
    # CSV/Sheets ì´ˆê¸°í™”
    csv_success = init_csv_file()
    gsheet_success = init_google_sheets()
    
    if csv_success:
        logger.info("âœ… CSV logging enabled")
    if gsheet_success:
        logger.info("âœ… Google Sheets logging enabled")
    
    # Redis ì´ˆê¸°í™”
    await init_redis()
    
    # Background tasks
    asyncio.create_task(health_check_monitor())
    asyncio.create_task(queue_processor())
    
    logger.info("=" * 70)
    logger.info("âœ… REXA Bot Server started!")
    logger.info(f"   - Model: solar-mini")
    logger.info(f"   - RAG chunks: {len(chunk_embeddings)}")
    logger.info(f"   - Redis: {'connected' if redis_client else 'in-memory'}")
    logger.info("=" * 70)

@app.on_event("shutdown")
async def shutdown_event():
    """Cleanup resources"""
    logger.info("ğŸ‘‹ Shutting down REXA Bot Server...")
    await close_redis()
    logger.info("âœ… Shutdown complete")
